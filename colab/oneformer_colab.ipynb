{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcPXP4QTFnIg"
      },
      "source": [
        "# ğŸ—ï¸ **OneFormer: One Transformer to Rule Universal Image Segmentation** ğŸ—ï¸\n",
        "\n",
        "## CVPR 2023\n",
        "\n",
        "[[`Project Page`](https://praeclarumjj3.github.io/oneformer/)] [[`arXiv`](https://arxiv.org/abs/2211.06220)] [[`GitHub`](https://github.com/SHI-Labs/OneFormer)] [[`HuggingFace Space`](https://huggingface.co/spaces/shi-labs/OneFormer)] [[`HuggingFace transformers`](https://huggingface.co/docs/transformers/main/en/model_doc/oneformer)]\n",
        "\n",
        "![Teaser](https://praeclarumjj3.github.io/oneformer/teaser.svg)\n",
        "\n",
        "#### OneFormer is the **first** multi-task universal image segmentation framework based on transformers. OneFormer needs to be trained only once with a single universal architecture, a single model, and on a single dataset , to outperform existing frameworks across semantic, instance, and panoptic segmentation tasks!\n",
        "\n",
        "\n",
        "\n",
        "This notebook provides a quickstart guide to using OneFormer for inference on images. We hope OneFormer inspires more research into developing train-once universal image segmentation frameworks. âœŒ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df70JDWc13OQ"
      },
      "source": [
        "#### If you found OneFormer useful in your research, please consider starring â­ us on [[`GitHub`](https://github.com/SHI-Labs/OneFormer)] and citing ğŸ“š us in your research!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoYYWnCuVaWU"
      },
      "source": [
        "# Setup OneFormer Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUmK767kWQlq",
        "outputId": "7572984b-eb2d-4584-a984-48e3775ff5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'OneFormer-Colab'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 141 (delta 6), reused 6 (delta 6), pack-reused 128 (from 1)\u001b[K\n",
            "Receiving objects: 100% (141/141), 6.73 MiB | 33.79 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n",
            "/content/OneFormer\n"
          ]
        }
      ],
      "source": [
        "######\n",
        "#@title 1. Clone OneFormer Repo\n",
        "######\n",
        "%cd /content/\n",
        "!rm -rf OneFormer/\n",
        "!git clone https://github.com/SHI-Labs/OneFormer-Colab.git\n",
        "! mv OneFormer-Colab OneFormer\n",
        "%cd /content/OneFormer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzVUqlOwHOBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5385b8b0-cf65-44aa-d1c1-e1d78cb39bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for natten (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 423, in run\n",
            "    _, build_failures = build(\n",
            "                        ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/wheel_builder.py\", line 319, in build\n",
            "    wheel_file = _build_one(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/wheel_builder.py\", line 193, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/wheel_builder.py\", line 240, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "             ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1477, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 695, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 645, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 728, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 413, in _extract_from_extended_frame_gen\n",
            "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 350, in _walk_tb_with_full_positions\n",
            "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 364, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for panopticapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for cityscapesScripts (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "######\n",
        "#@title 2. Install Dependencies.\n",
        "#@markdown It may take several minutes for all installations to finish.\n",
        "######\n",
        "\n",
        "# # Install opencv (required for running the demo)\n",
        "!pip3 install -U opencv-python --quiet\n",
        "!pip3 install natten -f https://shi-labs.com/natten/wheels/cu113/torch1.10.1/index.html --quiet\n",
        "\n",
        "# # # Install other dependencies\n",
        "!pip3 install git+https://github.com/cocodataset/panopticapi.git --quiet\n",
        "!pip3 install git+https://github.com/mcordts/cityscapesScripts.git --quiet\n",
        "\n",
        "!pip3 install -r requirements.txt --quiet\n",
        "!pip3 install ipython-autotime --quiet\n",
        "!pip3 install imutils --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os, distutils.core\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])} --quiet\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))"
      ],
      "metadata": {
        "id": "dDg7op2CuaFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw41v_NH8vM9"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title 3. Import Libraries and other Utilities\n",
        "######\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "setup_logger(name=\"oneformer\")\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "import imutils\n",
        "\n",
        "# Import detectron2 utilities\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.projects.deeplab import add_deeplab_config\n",
        "from detectron2.data import MetadataCatalog\n",
        "from demo.defaults import DefaultPredictor\n",
        "from demo.visualizer import Visualizer, ColorMode\n",
        "\n",
        "\n",
        "# import OneFormer Project\n",
        "from oneformer import (\n",
        "    add_oneformer_config,\n",
        "    add_common_config,\n",
        "    add_swin_config,\n",
        "    add_dinat_config,\n",
        "    add_convnext_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLH-GzQCxw53"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title 4. Define helper functions\n",
        "######\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "SWIN_CFG_DICT = {\"cityscapes\": \"configs/cityscapes/oneformer_swin_large_IN21k_384_bs16_90k.yaml\",\n",
        "            \"coco\": \"configs/coco/oneformer_swin_large_IN21k_384_bs16_100ep.yaml\",\n",
        "            \"ade20k\": \"configs/ade20k/oneformer_swin_large_IN21k_384_bs16_160k.yaml\",}\n",
        "\n",
        "DINAT_CFG_DICT = {\"cityscapes\": \"configs/cityscapes/oneformer_dinat_large_bs16_90k.yaml\",\n",
        "            \"coco\": \"configs/coco/oneformer_dinat_large_bs16_100ep.yaml\",\n",
        "            \"ade20k\": \"configs/ade20k/oneformer_dinat_large_IN21k_384_bs16_160k.yaml\",}\n",
        "\n",
        "def setup_cfg(dataset, model_path, use_swin):\n",
        "    # load config from file and command-line arguments\n",
        "    cfg = get_cfg()\n",
        "    add_deeplab_config(cfg)\n",
        "    add_common_config(cfg)\n",
        "    add_swin_config(cfg)\n",
        "    add_dinat_config(cfg)\n",
        "    add_convnext_config(cfg)\n",
        "    add_oneformer_config(cfg)\n",
        "    if use_swin:\n",
        "      cfg_path = SWIN_CFG_DICT[dataset]\n",
        "    else:\n",
        "      cfg_path = DINAT_CFG_DICT[dataset]\n",
        "    cfg.merge_from_file(cfg_path)\n",
        "    cfg.MODEL.DEVICE = 'cpu'\n",
        "    cfg.MODEL.WEIGHTS = model_path\n",
        "    cfg.freeze()\n",
        "    return cfg\n",
        "\n",
        "def setup_modules(dataset, model_path, use_swin):\n",
        "    cfg = setup_cfg(dataset, model_path, use_swin)\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "    metadata = MetadataCatalog.get(\n",
        "        cfg.DATASETS.TEST_PANOPTIC[0] if len(cfg.DATASETS.TEST_PANOPTIC) else \"__unused\"\n",
        "    )\n",
        "    if 'cityscapes_fine_sem_seg_val' in cfg.DATASETS.TEST_PANOPTIC[0]:\n",
        "        from cityscapesscripts.helpers.labels import labels\n",
        "        stuff_colors = [k.color for k in labels if k.trainId != 255]\n",
        "        metadata = metadata.set(stuff_colors=stuff_colors)\n",
        "\n",
        "    return predictor, metadata\n",
        "\n",
        "def panoptic_run(img, predictor, metadata):\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
        "    predictions = predictor(img, \"panoptic\")\n",
        "    panoptic_seg, segments_info = predictions[\"panoptic_seg\"]\n",
        "    out = visualizer.draw_panoptic_seg_predictions(\n",
        "    panoptic_seg.to(cpu_device), segments_info, alpha=0.5\n",
        ")\n",
        "    return out\n",
        "\n",
        "def instance_run(img, predictor, metadata):\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
        "    predictions = predictor(img, \"instance\")\n",
        "    instances = predictions[\"instances\"].to(cpu_device)\n",
        "    out = visualizer.draw_instance_predictions(predictions=instances, alpha=0.5)\n",
        "    return out\n",
        "\n",
        "def semantic_run(img, predictor, metadata):\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
        "    predictions = predictor(img, \"semantic\")\n",
        "    out = visualizer.draw_sem_seg(\n",
        "        predictions[\"sem_seg\"].argmax(dim=0).to(cpu_device), alpha=0.5\n",
        "    )\n",
        "    return out\n",
        "\n",
        "TASK_INFER = {\"panoptic\": panoptic_run,\n",
        "              \"instance\": instance_run,\n",
        "              \"semantic\": semantic_run}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a"
      },
      "source": [
        "# Run Inference using OneFormer on CPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKyUL4pngvE"
      },
      "source": [
        "## ADE20K Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xX8TLytOVal8"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@markdown We use `DiNAT-L` as the default backbone. To use Swin-L as backbone, select the checkbox below.\n",
        "use_swin = False #@param {type: 'boolean'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ldq3OJUzVl2"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title A. Initialize Model\n",
        "######\n",
        "# download model checkpoint\n",
        "import os\n",
        "import subprocess\n",
        "if not use_swin:\n",
        "  if not os.path.exists(\"250_16_dinat_l_oneformer_ade20k_160k.pth\"):\n",
        "    subprocess.run('wget https://shi-labs.com/projects/oneformer/ade20k/250_16_dinat_l_oneformer_ade20k_160k.pth', shell=True)\n",
        "  predictor, metadata = setup_modules(\"ade20k\", \"250_16_dinat_l_oneformer_ade20k_160k.pth\", use_swin)\n",
        "else:\n",
        "  if not os.path.exists(\"250_16_swin_l_oneformer_ade20k_160k.pth\"):\n",
        "    subprocess.run('wget https://shi-labs.com/projects/oneformer/ade20k/250_16_swin_l_oneformer_ade20k_160k.pth', shell=True)\n",
        "  predictor, metadata = setup_modules(\"ade20k\", \"250_16_swin_l_oneformer_ade20k_160k.pth\", use_swin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq9GY37ml1kr"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title B. Display Sample Image. You can modify the path and try your own images!\n",
        "######\n",
        "\n",
        "# change path here for another image\n",
        "img = cv2.imread(\"samples/ade20k.jpeg\")\n",
        "img = imutils.resize(img, width=640)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUjkwRsOn1O0"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title C. Run Inference (CPU)\n",
        "#@markdown Specify the **task**. `Default: panoptic`. Execution may take upto 2 minutes\n",
        "######\n",
        "###### Specify Task Here ######\n",
        "task = \"panoptic\" #@param\n",
        "##############################\n",
        "%load_ext autotime\n",
        "out = TASK_INFER[task](img, predictor, metadata).get_image()\n",
        "cv2_imshow(out[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyKgDthKDTVt"
      },
      "source": [
        "## Cityscapes Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LvWKWrl8V_4_"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@markdown We use `DiNAT-L` as the default backbone. To use Swin-L as backbone, select the checkbox below.\n",
        "use_swin = False #@param {type: 'boolean'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cek_0PhgDTV1"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title A. Initialize Model\n",
        "######\n",
        "# download model checkpoint\n",
        "import os\n",
        "import subprocess\n",
        "if not use_swin:\n",
        "  if not os.path.exists(\"250_16_dinat_l_oneformer_cityscapes_90k.pth\"):\n",
        "    subprocess.run('wget https://shi-labs.com/projects/oneformer/cityscapes/250_16_dinat_l_oneformer_cityscapes_90k.pth', shell=True)\n",
        "  predictor, metadata = setup_modules(\"cityscapes\", \"250_16_dinat_l_oneformer_cityscapes_90k.pth\", use_swin)\n",
        "else:\n",
        "  if not os.path.exists(\"250_16_swin_l_oneformer_cityscapes_90k.pth\"):\n",
        "    subprocess.run('wget https://shi-labs.com/projects/oneformer/cityscapes/250_16_swin_l_oneformer_cityscapes_90k.pth', shell=True)\n",
        "  predictor, metadata = setup_modules(\"cityscapes\", \"250_16_swin_l_oneformer_cityscapes_90k.pth\", use_swin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvkqpNdBDTV2"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title B. Display Sample Image. You can modify the path and try your own images!\n",
        "######\n",
        "\n",
        "# change path here for another image\n",
        "img = cv2.imread(\"samples/cityscapes.png\")\n",
        "img = imutils.resize(img, width=512)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPqny7PmDTV2"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title C. Run Inference (CPU)\n",
        "#@markdown Specify the **task**. `Default: panoptic`. Execution may take upto 2 minutes\n",
        "######\n",
        "task = \"panoptic\" #@param\n",
        "%load_ext autotime\n",
        "out = TASK_INFER[task](img, predictor, metadata).get_image()\n",
        "cv2_imshow(out[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lowI8uz4Qep9"
      },
      "source": [
        "## COCO Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "867pk7CoWCHl"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@markdown We use `DiNAT-L` as the default backbone. To use Swin-L as backbone, select the checkbox below.\n",
        "use_swin = False #@param {type: 'boolean'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfggTxANQeqF"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title A. Initialize Model\n",
        "######\n",
        "# download model checkpoint\n",
        "import os\n",
        "import subprocess\n",
        "if not use_swin:\n",
        "  if not os.path.exists(\"150_16_dinat_l_oneformer_coco_100ep.pth\"):\n",
        "    subprocess.run('wget https://shi-labs.com/projects/oneformer/coco/150_16_dinat_l_oneformer_coco_100ep.pth', shell=True)\n",
        "  predictor, metadata = setup_modules(\"coco\", \"150_16_dinat_l_oneformer_coco_100ep.pth\", use_swin)\n",
        "else:\n",
        "  if not os.path.exists(\"150_16_swin_l_oneformer_coco_100ep.pth\"):\n",
        "    subprocess.run('wget https://shi-labs.com/projects/oneformer/coco/150_16_swin_l_oneformer_coco_100ep.pth', shell=True)\n",
        "  predictor, metadata = setup_modules(\"coco\", \"150_16_swin_l_oneformer_coco_100ep.pth\", use_swin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyj_hdt9QeqG"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title B. Display Sample Image. You can modify the path and try your own images!\n",
        "######\n",
        "\n",
        "# change path here for another image\n",
        "img = cv2.imread(\"samples/coco.jpeg\")\n",
        "img = imutils.resize(img, width=512)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2rD44_rQeqG"
      },
      "outputs": [],
      "source": [
        "######\n",
        "#@title C. Run Inference (CPU)\n",
        "#@markdown Specify the **task**. `Default: panoptic`. Execution may take upto 2 minutes\n",
        "######\n",
        "task = \"panoptic\" #@param\n",
        "%load_ext autotime\n",
        "out = TASK_INFER[task](img, predictor, metadata).get_image()\n",
        "cv2_imshow(out[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoZptOo2UNQ0"
      },
      "source": [
        "# More Information on OneFormer ğŸ—ï¸\n",
        "- [Project Page](https://praeclarumjj3.github.io/oneformer/)\n",
        "- [GitHub Repo](https://SHI-Labs/OneFormer)\n",
        "- [ArXiv preprint](https://arxiv.org/abs/2211.06220)\n",
        "- [HuggingFace Space](https://huggingface.co/spaces/shi-labs/OneFormer)\n",
        "- [HuggingFace transformers](https://huggingface.co/docs/transformers/main/en/model_doc/oneformer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}